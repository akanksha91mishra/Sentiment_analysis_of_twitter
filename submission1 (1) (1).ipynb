{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/akankshamishra/Downloads'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/akankshamishra/Desktop/hackathon 2/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                            tweet  \\\n",
      "9082  #Apple to Hawk iPad 2 at #SXSW Festival Popup Store!  {link}  by @mention                                                     \n",
      "9083  Hey @mention ask Dennis why no iPad app?  #SXSW #checkins                                                                     \n",
      "9084  RT @mention Find where @mention is playing at #SXSW on the #eventseekr app for Android. We got u! {link}                      \n",
      "9085  It's not a rumor: Apple is opening up a temporary store in downtown Austin for #SXSW and the iPad 2 launch {link}             \n",
      "9086  Apple store coming 2 Austin for SXSW.   RT: &quot;@mention Before It Even Begins, Apple Wins #SXSW {link} on @mention         \n",
      "9087  @mention @mention @mention Hmmm....how fast can #apple build a new store in time for #sxsw  {link}                            \n",
      "9088  Samsung Galaxy S II Appears At FCC And Team Android #SXSW Party {link} via @mention                                           \n",
      "9089  @mention You could buy a new iPad 2 tmrw at the Apple pop-up store at #sxsw: {link}                                           \n",
      "9090  Wow very long queue of people at apple pop up store now, some have bought 3 iPads! #sxsw@mention Room#NokiaConnects           \n",
      "9091  Privacy Could Headline Google Circles Social Network Reveal Later Today [Social Networks] {link} #ACLU #GoogleCircles #SXSW   \n",
      "\n",
      "     test/train  \n",
      "9082  test       \n",
      "9083  test       \n",
      "9084  test       \n",
      "9085  test       \n",
      "9086  test       \n",
      "9087  test       \n",
      "9088  test       \n",
      "9089  test       \n",
      "9090  test       \n",
      "9091  test       \n"
     ]
    }
   ],
   "source": [
    "#Load csv\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train[\"test/train\"] = \"train\"\n",
    "train=train.dropna()\n",
    "#print(train.head(10))\n",
    "test[\"test/train\"] = \"test\"\n",
    "train_corpus = train[['tweet','test/train']]\n",
    "test_corpus = test[['tweet','test/train']]\n",
    "corpus = pd.concat([train_corpus,test_corpus],ignore_index=True)\n",
    "print(corpus.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the most in-your-face ex. of stealing the show in yrs RT @mention &quot;At #SXSW, Apple schools the mkt experts&quot;  {link}\n",
      "<class 'str'>\n",
      "one of the most in-your-face ex. of stealing the show in yrs RT @mention &quot;At #SXSW, Apple schools the mkt experts&quot;  {link}\n"
     ]
    }
   ],
   "source": [
    "type(corpus)\n",
    "text = corpus[\"tweet\"][2]\n",
    "print(text)\n",
    "print(type(text))\n",
    "text = train[\"tweet\"][2]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_corpus = train[\"tweet\"].tolist()\n",
    "#train_label = train[\"sentiment\"].tolist()\n",
    "#test_corpus = test[\"tweet\"].tolist()\n",
    "#test_label = test[\"sentiment\"].tolist()\n",
    "#data = train_corpus + test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id  \\\n",
      "0  1701       \n",
      "1  1851       \n",
      "2  2689       \n",
      "3  4525       \n",
      "4  3604       \n",
      "5  966        \n",
      "6  1395       \n",
      "7  8182       \n",
      "8  8835       \n",
      "9  883        \n",
      "\n",
      "                                                                                                                                             tweet  \\\n",
      "0  #sxswnui #sxsw #apple defining language of touch with different dialects becoming smaller                                                         \n",
      "1  Learning ab Google doodles! All doodles should be light, funny &amp; innovative, with exceptions for significant occasions. #GoogleDoodle #sxsw   \n",
      "2  one of the most in-your-face ex. of stealing the show in yrs RT @mention &quot;At #SXSW, Apple schools the mkt experts&quot;  {link}              \n",
      "3  This iPhone #SXSW app would b pretty awesome if it didn't crash every 10mins during extended browsing. #Fuckit #Illmakeitwork                     \n",
      "4  Line outside the Apple store in Austin waiting for the new iPad #SXSW  {link}                                                                     \n",
      "5  #technews One lone dude awaits iPad 2 at AppleÛªs SXSW store {link} #Tech_News #Apple #iPad_2 #SXSW #tablets #tech                               \n",
      "6  SXSW Tips, Prince, NPR Videos, Toy Shopping With Zuckerberg.\\r\\n{link}  #sxsw  #ipad                                                              \n",
      "7  NU user RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by #Mashable                           \n",
      "8  Free #SXSW sampler on iTunes {link} #FreeMusic                                                                                                    \n",
      "9  I think I might go all weekend without seeing the same iPad case twice... #sxsw                                                                   \n",
      "\n",
      "   sentiment test/train  \n",
      "0  1          train      \n",
      "1  1          train      \n",
      "2  2          train      \n",
      "3  0          train      \n",
      "4  1          train      \n",
      "5  1          train      \n",
      "6  1          train      \n",
      "7  1          train      \n",
      "8  2          train      \n",
      "9  2          train      \n",
      "Test dataset\n",
      "   tweet_id  \\\n",
      "0  7506       \n",
      "1  7992       \n",
      "2  247        \n",
      "3  7688       \n",
      "4  3294       \n",
      "5  6125       \n",
      "6  6131       \n",
      "7  4134       \n",
      "8  8206       \n",
      "9  8552       \n",
      "\n",
      "                                                                                                                                         tweet  \\\n",
      "0  Audience Q: What prototyping tools do you use? Sketchbooks/sharpie pens, photoshop, Balsamic, Google docs, Axsure, etc. #myprototype #sxsw    \n",
      "1  At SXSW? Send Your Best Photos &amp; Videos to... {link} #citizen_journalism #cnn #ireport #photography #sxsw #Cyber #iPhone                  \n",
      "2  @mention  and here's a pic of you winning your ipad! #unsix #sxsw cc @mention @mention  {link} (cont) {link}                                  \n",
      "3  Google Marissa Mayer: mobile phone as a cursor of physical location - new version of map fast and more real life like   #sxsw                 \n",
      "4  #SXSW Google maps is even cooler than I thought                                                                                               \n",
      "5  RT @mention In front of @mention popup store at #SXSW last night {link}                                                                       \n",
      "6  RT @mention In my next life I'm coming back as an iPad 2. Women can't keep their hands off this thing. #SXSW                                  \n",
      "7  Google celebrating Pi Day in style at #SXSW -  {link}                                                                                         \n",
      "8  Hmmm is it a bit weird that #sxsw is not tending but Google Circle is?                                                                        \n",
      "9  @mention to launch 'Circles' later today at #SXSW?? gotta love #SXSW - one platform for everything from Independent film to Innovative Tech   \n",
      "\n",
      "  test/train  \n",
      "0  test       \n",
      "1  test       \n",
      "2  test       \n",
      "3  test       \n",
      "4  test       \n",
      "5  test       \n",
      "6  test       \n",
      "7  test       \n",
      "8  test       \n",
      "9  test       \n"
     ]
    }
   ],
   "source": [
    "print(train.head(10))\n",
    "print(\"Test dataset\")\n",
    "print(test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4310\n",
       "2    2382\n",
       "0    456 \n",
       "3    125 \n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VALUE COUNTS\n",
    "#0 -> Negative sentiment\n",
    "#1 -> Neutral sentiment\n",
    "#2 -> Positive sentiment\n",
    "#3 -> Can't tell\n",
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id      0\n",
       "tweet         0\n",
       "sentiment     0\n",
       "test/train    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One blank tweet deleting it\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id      0\n",
       "tweet         0\n",
       "test/train    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>test/train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701</td>\n",
       "      <td>#sxswnui #sxsw #apple defining language of touch with different dialects becoming smaller</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851</td>\n",
       "      <td>Learning ab Google doodles! All doodles should be light, funny &amp;amp; innovative, with exceptions for significant occasions. #GoogleDoodle #sxsw</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2689</td>\n",
       "      <td>one of the most in-your-face ex. of stealing the show in yrs RT @mention &amp;quot;At #SXSW, Apple schools the mkt experts&amp;quot;  {link}</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4525</td>\n",
       "      <td>This iPhone #SXSW app would b pretty awesome if it didn't crash every 10mins during extended browsing. #Fuckit #Illmakeitwork</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3604</td>\n",
       "      <td>Line outside the Apple store in Austin waiting for the new iPad #SXSW  {link}</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>966</td>\n",
       "      <td>#technews One lone dude awaits iPad 2 at AppleÛªs SXSW store {link} #Tech_News #Apple #iPad_2 #SXSW #tablets #tech</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1395</td>\n",
       "      <td>SXSW Tips, Prince, NPR Videos, Toy Shopping With Zuckerberg.\\r\\n{link}  #sxsw  #ipad</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8182</td>\n",
       "      <td>NU user RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by #Mashable</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8835</td>\n",
       "      <td>Free #SXSW sampler on iTunes {link} #FreeMusic</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>883</td>\n",
       "      <td>I think I might go all weekend without seeing the same iPad case twice... #sxsw</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6398</td>\n",
       "      <td>RT @mention Official #SXSW App Û÷SXSW GOÛª bit.ly/hmiiGa #android #iphone #ipad</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2369</td>\n",
       "      <td>It's official! I'm buying an iPad. #SXSW #elevate</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3944</td>\n",
       "      <td>They're giving away iPad 2's, x boxes and books at @mention #sxsw #techenvy</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6909</td>\n",
       "      <td>RT @mention We're officially at #SXSW! Come by the @mention Grill, mention us w/ #zazzlsxsw and youÛªll get to make your own iPhone case!</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7917</td>\n",
       "      <td>#Companies to watch, from the #SXSW trade show floor {link} #apps #features #hardware #ipad #iphone</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5849</td>\n",
       "      <td>RT @mention Google Marissa Mayer, future of location: augmented reality, contextual discovery, make smartphones smarter. #sxsw</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1955</td>\n",
       "      <td>DL the #Calyp App to get into #Calyp Casa at #SXSW the free mobile app is available in iTunes App Store &amp;amp; Android Market. See u there!</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1472</td>\n",
       "      <td>Well yeah.  Music &amp;gt; iPhone nerds RT @mention my god, cute girls everywhere...I love when interactive ends and music begins #sxsw</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4730</td>\n",
       "      <td>Apple Opens Pop Up Store at SXSW {link} via @mention #apple #iPad2 #technology #iTunes #SXSW</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2166</td>\n",
       "      <td>@mention atleast you are at #sxsw. I'm not there AND I have no Ipad. #doubleloser</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3497</td>\n",
       "      <td>Cue the choir music #SXSW  @mention Apple Store, SXSW {link}</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>165</td>\n",
       "      <td>Anyone at #sxsw want an iPad 2? I'm in line and will pick one up for someone willing to pay me 50 for me to grab 1 for you?</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1352</td>\n",
       "      <td>_¼ÛÄ___ü ___¡  _____«_µ... &amp;gt;&amp;gt; @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6431</td>\n",
       "      <td>RT @mention P.S. @mention and Google throw a b!tchin' party. Shout out to The Spazmatics #sxsw</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>634</td>\n",
       "      <td>.@mention I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4544</td>\n",
       "      <td>does anyone know if google did talk about #circles at #SXSW ?</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>568</td>\n",
       "      <td>ÛÏ@mention Google set to launch new social network #Circles today at #sxswÛ @mention  @mention</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>775</td>\n",
       "      <td>Google to Launch Major New Social Network Called Circles, Possibly Today {link} #SXSW</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5368</td>\n",
       "      <td>standing on a long line surrounded by unemployed techies from brooklyn!  am i at #sxsw or at the apple store on 5th ave waiting for ipad?!</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3087</td>\n",
       "      <td>WOW! *Something Ventured* was a kick ass film... Google or blekko it for details. Good choice @mention #sxsw #startups #VC #movie #awesome</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7244</th>\n",
       "      <td>4996</td>\n",
       "      <td>Google looks to the future with mobile, location-based devices | {link}  #SXSW</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7245</th>\n",
       "      <td>4887</td>\n",
       "      <td>Fantastico! RT @mention Marissa Mayer: Google Will Connect the Digital &amp;amp; Physical Worlds Through Mobile - {link} #sxsw</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7246</th>\n",
       "      <td>5027</td>\n",
       "      <td>RT @mention \\r\\nAn Apple pop-uitp store at #SXSW? There goes my impulse control. j.mp/i41H53 &amp;lt;- See, this is why it's good I'm not there #ooc</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7247</th>\n",
       "      <td>409</td>\n",
       "      <td>wishes he could be at the @mention / @mention / @mention party at #sxsw instead of doing homework for tomorrow...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7248</th>\n",
       "      <td>392</td>\n",
       "      <td>Tomorrow, Charles Chen will be speaking about Android and ChromeOS access @mention the Google booth in Exhibit Hall 3 @mention 1PM #sxsw</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7249</th>\n",
       "      <td>2556</td>\n",
       "      <td>Z7: Lead Don't Follow {link} [codes valid: 4:00-7:59:59p 03/11/11] #infektd #sxsw #zlf</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>5467</td>\n",
       "      <td>RT @mention Apple sets up 5,000-square-foot temporary store at #SXSW to sell new iPads, test potential traffic {link}</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7251</th>\n",
       "      <td>5290</td>\n",
       "      <td>RT @mention #SXSW gear bag: iPad 2, iPhone, Mophie. Traveling light this year! {link}</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7252</th>\n",
       "      <td>7145</td>\n",
       "      <td>Û÷Viagra for your communicationsÛª @mention launches Android app at #SXSW {link} Happy to see expansion beyond Outlook plugin.</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7253</th>\n",
       "      <td>4635</td>\n",
       "      <td>Interesting! RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7254</th>\n",
       "      <td>780</td>\n",
       "      <td>Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw @mention</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7255</th>\n",
       "      <td>7424</td>\n",
       "      <td>Sweet, Apple's opening a pop-up shop in the Scarbrough Building on Congress for the iPad 2 - {link} /via @mention #sxsw</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7256</th>\n",
       "      <td>6739</td>\n",
       "      <td>RT @mention the future is about networks, not just data. that's why google may not win long term #SXSW #web3 #SaatchiNY</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7257</th>\n",
       "      <td>3891</td>\n",
       "      <td>Did you miss Google's VP of Search, Marissa Mayer last week? Listen to the interview here  {link} #SXSW</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7258</th>\n",
       "      <td>4284</td>\n",
       "      <td>@mention massive lines at #sxsw apple store...agree, I can wait. Perhaps late early adopter?</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>1179</td>\n",
       "      <td>Exploring the World in 3D with XML combines Google Earth w/ location of individuals to show where you've been over time. So cool! #SxSW</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7260</th>\n",
       "      <td>6157</td>\n",
       "      <td>RT @mention iPad hipster #AustinCrowd #SXSW {link}</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7261</th>\n",
       "      <td>3525</td>\n",
       "      <td>The new Whrrl app is now live in the iPhone app store AND Android marketplace. Get it while it's hot! (Just in time for #SXSW!) via @mention</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7262</th>\n",
       "      <td>8056</td>\n",
       "      <td>Come see something new about Google SketchUp Pro at #SXSW {link} via @mention Google SketchUp Blog</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7263</th>\n",
       "      <td>1273</td>\n",
       "      <td>There are two apple stores in ATX!! RT @mention The iPad 2 goes on sale next Friday...the Austin Apple Store is going to be busy! #SXSWÛ</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7264</th>\n",
       "      <td>8775</td>\n",
       "      <td>Heading over to ballroom b 'your mom has an ipad-designing for boomers' #sxsw</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>287</td>\n",
       "      <td>At #SXSW, Apple schools the marketing experts | CNET Blogs {link} #Austin #ATX #retail</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>3362</td>\n",
       "      <td>@mention great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>5222</td>\n",
       "      <td>The session #designingforkids is changing my mind about my future kid's relationship with the iPhone. #sapient #sxsw</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7268</th>\n",
       "      <td>8644</td>\n",
       "      <td>Great visualisation of the ghost movement logic in PacMan during the Google Doodles session @mention #sxsw. More details here. {link}</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>3343</td>\n",
       "      <td>@mention Google plze Tammi.  I'm in middle of #SXSW craziness and everything is soooooo busy!</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>5334</td>\n",
       "      <td>RT @mention ÷¼ Are you all set? ÷_ {link} ÷_ #edchat #musedchat #sxsw #sxswi #newTwitter</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>5378</td>\n",
       "      <td>RT @mention Aha! Found proof of lactation room, excuse me, &amp;quot;Mother's Room,&amp;quot; brought to you by Google, at last year's #SXSW. {link}</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>2173</td>\n",
       "      <td>We just launched our iPad app at #SXSW! Get all the details + the first edition FREE: {link}</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>3162</td>\n",
       "      <td>The next fin serv battle is vs Apple, GOOG, Mobile operators. They have consumer loyalty and tons of cash (vs. Banks) #bankinnovate #SXSW</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7273 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id  \\\n",
       "0     1701       \n",
       "1     1851       \n",
       "2     2689       \n",
       "3     4525       \n",
       "4     3604       \n",
       "5     966        \n",
       "6     1395       \n",
       "7     8182       \n",
       "8     8835       \n",
       "9     883        \n",
       "10    6398       \n",
       "11    2369       \n",
       "12    3944       \n",
       "13    6909       \n",
       "14    7917       \n",
       "15    5849       \n",
       "16    1955       \n",
       "17    1472       \n",
       "18    4730       \n",
       "19    2166       \n",
       "20    3497       \n",
       "21    165        \n",
       "22    1352       \n",
       "23    6431       \n",
       "24    634        \n",
       "25    4544       \n",
       "26    568        \n",
       "27    775        \n",
       "28    5368       \n",
       "29    3087       \n",
       "...    ...       \n",
       "7244  4996       \n",
       "7245  4887       \n",
       "7246  5027       \n",
       "7247  409        \n",
       "7248  392        \n",
       "7249  2556       \n",
       "7250  5467       \n",
       "7251  5290       \n",
       "7252  7145       \n",
       "7253  4635       \n",
       "7254  780        \n",
       "7255  7424       \n",
       "7256  6739       \n",
       "7257  3891       \n",
       "7258  4284       \n",
       "7259  1179       \n",
       "7260  6157       \n",
       "7261  3525       \n",
       "7262  8056       \n",
       "7263  1273       \n",
       "7264  8775       \n",
       "7265  287        \n",
       "7266  3362       \n",
       "7267  5222       \n",
       "7268  8644       \n",
       "7269  3343       \n",
       "7270  5334       \n",
       "7271  5378       \n",
       "7272  2173       \n",
       "7273  3162       \n",
       "\n",
       "                                                                                                                                                 tweet  \\\n",
       "0     #sxswnui #sxsw #apple defining language of touch with different dialects becoming smaller                                                          \n",
       "1     Learning ab Google doodles! All doodles should be light, funny &amp; innovative, with exceptions for significant occasions. #GoogleDoodle #sxsw    \n",
       "2     one of the most in-your-face ex. of stealing the show in yrs RT @mention &quot;At #SXSW, Apple schools the mkt experts&quot;  {link}               \n",
       "3     This iPhone #SXSW app would b pretty awesome if it didn't crash every 10mins during extended browsing. #Fuckit #Illmakeitwork                      \n",
       "4     Line outside the Apple store in Austin waiting for the new iPad #SXSW  {link}                                                                      \n",
       "5     #technews One lone dude awaits iPad 2 at AppleÛªs SXSW store {link} #Tech_News #Apple #iPad_2 #SXSW #tablets #tech                                \n",
       "6     SXSW Tips, Prince, NPR Videos, Toy Shopping With Zuckerberg.\\r\\n{link}  #sxsw  #ipad                                                               \n",
       "7     NU user RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by #Mashable                            \n",
       "8     Free #SXSW sampler on iTunes {link} #FreeMusic                                                                                                     \n",
       "9     I think I might go all weekend without seeing the same iPad case twice... #sxsw                                                                    \n",
       "10    RT @mention Official #SXSW App Û÷SXSW GOÛª bit.ly/hmiiGa #android #iphone #ipad                                                                  \n",
       "11    It's official! I'm buying an iPad. #SXSW #elevate                                                                                                  \n",
       "12    They're giving away iPad 2's, x boxes and books at @mention #sxsw #techenvy                                                                        \n",
       "13    RT @mention We're officially at #SXSW! Come by the @mention Grill, mention us w/ #zazzlsxsw and youÛªll get to make your own iPhone case!         \n",
       "14    #Companies to watch, from the #SXSW trade show floor {link} #apps #features #hardware #ipad #iphone                                                \n",
       "15    RT @mention Google Marissa Mayer, future of location: augmented reality, contextual discovery, make smartphones smarter. #sxsw                     \n",
       "16    DL the #Calyp App to get into #Calyp Casa at #SXSW the free mobile app is available in iTunes App Store &amp; Android Market. See u there!         \n",
       "17    Well yeah.  Music &gt; iPhone nerds RT @mention my god, cute girls everywhere...I love when interactive ends and music begins #sxsw                \n",
       "18    Apple Opens Pop Up Store at SXSW {link} via @mention #apple #iPad2 #technology #iTunes #SXSW                                                       \n",
       "19    @mention atleast you are at #sxsw. I'm not there AND I have no Ipad. #doubleloser                                                                  \n",
       "20    Cue the choir music #SXSW  @mention Apple Store, SXSW {link}                                                                                       \n",
       "21    Anyone at #sxsw want an iPad 2? I'm in line and will pick one up for someone willing to pay me 50 for me to grab 1 for you?                        \n",
       "22    _¼ÛÄ___ü ___¡  _____«_µ... &gt;&gt; @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw               \n",
       "23    RT @mention P.S. @mention and Google throw a b!tchin' party. Shout out to The Spazmatics #sxsw                                                     \n",
       "24    .@mention I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.                     \n",
       "25    does anyone know if google did talk about #circles at #SXSW ?                                                                                      \n",
       "26    ÛÏ@mention Google set to launch new social network #Circles today at #sxswÛ @mention  @mention                                                  \n",
       "27    Google to Launch Major New Social Network Called Circles, Possibly Today {link} #SXSW                                                              \n",
       "28    standing on a long line surrounded by unemployed techies from brooklyn!  am i at #sxsw or at the apple store on 5th ave waiting for ipad?!         \n",
       "29    WOW! *Something Ventured* was a kick ass film... Google or blekko it for details. Good choice @mention #sxsw #startups #VC #movie #awesome         \n",
       "...                                                                                                                                          ...         \n",
       "7244  Google looks to the future with mobile, location-based devices | {link}  #SXSW                                                                     \n",
       "7245  Fantastico! RT @mention Marissa Mayer: Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #sxsw                         \n",
       "7246  RT @mention \\r\\nAn Apple pop-uitp store at #SXSW? There goes my impulse control. j.mp/i41H53 &lt;- See, this is why it's good I'm not there #ooc   \n",
       "7247  wishes he could be at the @mention / @mention / @mention party at #sxsw instead of doing homework for tomorrow...                                  \n",
       "7248  Tomorrow, Charles Chen will be speaking about Android and ChromeOS access @mention the Google booth in Exhibit Hall 3 @mention 1PM #sxsw           \n",
       "7249  Z7: Lead Don't Follow {link} [codes valid: 4:00-7:59:59p 03/11/11] #infektd #sxsw #zlf                                                             \n",
       "7250  RT @mention Apple sets up 5,000-square-foot temporary store at #SXSW to sell new iPads, test potential traffic {link}                              \n",
       "7251  RT @mention #SXSW gear bag: iPad 2, iPhone, Mophie. Traveling light this year! {link}                                                              \n",
       "7252  Û÷Viagra for your communicationsÛª @mention launches Android app at #SXSW {link} Happy to see expansion beyond Outlook plugin.                   \n",
       "7253  Interesting! RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw                                     \n",
       "7254  Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw @mention                                                     \n",
       "7255  Sweet, Apple's opening a pop-up shop in the Scarbrough Building on Congress for the iPad 2 - {link} /via @mention #sxsw                            \n",
       "7256  RT @mention the future is about networks, not just data. that's why google may not win long term #SXSW #web3 #SaatchiNY                            \n",
       "7257  Did you miss Google's VP of Search, Marissa Mayer last week? Listen to the interview here  {link} #SXSW                                            \n",
       "7258  @mention massive lines at #sxsw apple store...agree, I can wait. Perhaps late early adopter?                                                       \n",
       "7259  Exploring the World in 3D with XML combines Google Earth w/ location of individuals to show where you've been over time. So cool! #SxSW            \n",
       "7260  RT @mention iPad hipster #AustinCrowd #SXSW {link}                                                                                                 \n",
       "7261  The new Whrrl app is now live in the iPhone app store AND Android marketplace. Get it while it's hot! (Just in time for #SXSW!) via @mention       \n",
       "7262  Come see something new about Google SketchUp Pro at #SXSW {link} via @mention Google SketchUp Blog                                                 \n",
       "7263  There are two apple stores in ATX!! RT @mention The iPad 2 goes on sale next Friday...the Austin Apple Store is going to be busy! #SXSWÛ         \n",
       "7264  Heading over to ballroom b 'your mom has an ipad-designing for boomers' #sxsw                                                                      \n",
       "7265  At #SXSW, Apple schools the marketing experts | CNET Blogs {link} #Austin #ATX #retail                                                             \n",
       "7266  @mention great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)                  \n",
       "7267  The session #designingforkids is changing my mind about my future kid's relationship with the iPhone. #sapient #sxsw                               \n",
       "7268  Great visualisation of the ghost movement logic in PacMan during the Google Doodles session @mention #sxsw. More details here. {link}              \n",
       "7269  @mention Google plze Tammi.  I'm in middle of #SXSW craziness and everything is soooooo busy!                                                      \n",
       "7270  RT @mention ÷¼ Are you all set? ÷_ {link} ÷_ #edchat #musedchat #sxsw #sxswi #newTwitter                                                        \n",
       "7271  RT @mention Aha! Found proof of lactation room, excuse me, &quot;Mother's Room,&quot; brought to you by Google, at last year's #SXSW. {link}       \n",
       "7272  We just launched our iPad app at #SXSW! Get all the details + the first edition FREE: {link}                                                       \n",
       "7273  The next fin serv battle is vs Apple, GOOG, Mobile operators. They have consumer loyalty and tons of cash (vs. Banks) #bankinnovate #SXSW          \n",
       "\n",
       "      sentiment test/train  \n",
       "0     1          train      \n",
       "1     1          train      \n",
       "2     2          train      \n",
       "3     0          train      \n",
       "4     1          train      \n",
       "5     1          train      \n",
       "6     1          train      \n",
       "7     1          train      \n",
       "8     2          train      \n",
       "9     2          train      \n",
       "10    3          train      \n",
       "11    2          train      \n",
       "12    2          train      \n",
       "13    1          train      \n",
       "14    1          train      \n",
       "15    1          train      \n",
       "16    1          train      \n",
       "17    2          train      \n",
       "18    1          train      \n",
       "19    1          train      \n",
       "20    1          train      \n",
       "21    1          train      \n",
       "22    2          train      \n",
       "23    2          train      \n",
       "24    0          train      \n",
       "25    1          train      \n",
       "26    1          train      \n",
       "27    1          train      \n",
       "28    3          train      \n",
       "29    1          train      \n",
       "...  ..            ...      \n",
       "7244  1          train      \n",
       "7245  2          train      \n",
       "7246  1          train      \n",
       "7247  1          train      \n",
       "7248  1          train      \n",
       "7249  1          train      \n",
       "7250  1          train      \n",
       "7251  1          train      \n",
       "7252  2          train      \n",
       "7253  1          train      \n",
       "7254  1          train      \n",
       "7255  2          train      \n",
       "7256  0          train      \n",
       "7257  1          train      \n",
       "7258  2          train      \n",
       "7259  2          train      \n",
       "7260  2          train      \n",
       "7261  2          train      \n",
       "7262  1          train      \n",
       "7263  2          train      \n",
       "7264  1          train      \n",
       "7265  2          train      \n",
       "7266  2          train      \n",
       "7267  3          train      \n",
       "7268  2          train      \n",
       "7269  1          train      \n",
       "7270  1          train      \n",
       "7271  1          train      \n",
       "7272  1          train      \n",
       "7273  1          train      \n",
       "\n",
       "[7273 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7273, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7273, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7273, 4)\n",
      "(1819, 3)\n",
      "tweet_id      0\n",
      "tweet         0\n",
      "sentiment     0\n",
      "test/train    0\n",
      "dtype: int64\n",
      "tweet_id      0\n",
      "tweet         0\n",
      "test/train    0\n",
      "dtype: int64\n",
      "(9092, 2)\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())\n",
    "print(corpus.shape)\n",
    "print(corpus[\"test/train\"][7272])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff_to_be_removed = list(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "cleaned_tweet=[]\n",
    "def preprocess_word(word):\n",
    "    # Remove punctuation\n",
    "    word = word.strip('\\'\"?!,.():;')\n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    return word\n",
    "\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Check if word begins with an alphabet\n",
    "    \n",
    "    return (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)\n",
    "\n",
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet\n",
    "\n",
    "def tweet_cleanining(tweet):\n",
    "    clean_tweet=[]\n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "    #Replace {}\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', 'USER_MENTION', tweet)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    #clean_tweet = \"Tweet cleaned\"\n",
    "    #Cleaning for each word\n",
    "    words = tweet.split()\n",
    "\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word) and word not in stuff_to_be_removed:\n",
    "        #    if use_stemmer:\n",
    "        #        word = str(porter_stemmer.stem(word))\n",
    "        #    word = word_tokenize(word)\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            clean_tweet.append(word)\n",
    "\n",
    "    return ' '.join(clean_tweet)\n",
    "\n",
    "#new_train = tweet_cleanining(train)\n",
    "\n",
    "#test_df = train[:30]\n",
    "for ind in corpus.index: \n",
    "    #print('Text before processing')\n",
    "    #text = corpus['tweet'][ind]\n",
    "    text = tweet_cleanining(corpus['tweet'][ind])\n",
    "    cleaned_tweet.append(text)\n",
    "    #train['tweet'][ind] = text\n",
    "    #print('Text after cleaning',text)\n",
    "\n",
    "corpus['cleaned_tweet'] = cleaned_tweet   \n",
    "#print(corpus['tweet'],corpus['cleaned_tweet'])    \n",
    "# For Test\n",
    "#test_cleaned_tweet=[]\n",
    "#for ind in test.index: \n",
    "    #print('Text before processing')\n",
    "    #print(train['tweet'][ind])\n",
    "   # text = tweet_cleanining(test['tweet'][ind])\n",
    "    #test_cleaned_tweet.append(text)\n",
    "    #train['tweet'][ind] = text\n",
    "    #print('Text after cleaning',text)\n",
    "\n",
    "#test['cleaned_tweet'] = cleaned_tweet   \n",
    "#print(train['tweet'],train['cleaned_tweet']) \n",
    "\n",
    "#new_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'tweet', 'sentiment', 'test/train'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector = tfidf.fit_transform(new_train[\"cleaned_tweet\"])\n",
    "vector = tfidf.fit_transform(corpus[\"cleaned_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7273, 4)\n",
      "test train\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(corpus['test/train'][7273],corpus['test/train'][7272])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_X = pd.DataFrame(vector.toarray(),columns=list(tfidf.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corpus_X[0:7273]\n",
    "X_submission = corpus_X[7273:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7273, 8268)\n",
      "(1819, 8268)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X,y,random_state=42,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6721649484536083\n",
      "[[ 15  58  13   2]\n",
      " [  8 743  94   4]\n",
      " [  2 272 219   2]\n",
      " [  2  18   2   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.17      0.26        88\n",
      "           1       0.68      0.88      0.77       849\n",
      "           2       0.67      0.44      0.53       495\n",
      "           3       0.11      0.04      0.06        23\n",
      "\n",
      "    accuracy                           0.67      1455\n",
      "   macro avg       0.50      0.38      0.41      1455\n",
      "weighted avg       0.66      0.67      0.64      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier(random_state=10))\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_rf = rf.score(X_test,y_test)\n",
    "confusion_mat_rf = confusion_matrix(y_test,y_pred)\n",
    "class_repo_rf = classification_report(y_test,y_pred)\n",
    "print(accuracy_rf)\n",
    "print(confusion_mat_rf)\n",
    "print(class_repo_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6790378006872853\n",
      "[[ 20  59   8   1]\n",
      " [  5 797  44   3]\n",
      " [  3 320 171   1]\n",
      " [  1  20   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.23      0.34        88\n",
      "           1       0.67      0.94      0.78       849\n",
      "           2       0.76      0.35      0.47       495\n",
      "           3       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.68      1455\n",
      "   macro avg       0.53      0.38      0.40      1455\n",
      "weighted avg       0.69      0.68      0.64      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = OneVsRestClassifier(SGDClassifier(max_iter=5, tol=None))\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "accuracy_sgd = sgd.score(X_test,y_test)\n",
    "confusion_mat_sgd = confusion_matrix(y_test,y_pred)\n",
    "class_repo_sgd = classification_report(y_test,y_pred)\n",
    "print(accuracy_sgd)\n",
    "print(confusion_mat_sgd)\n",
    "print(class_repo_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6707903780068728\n",
      "[[  0  76  12   0]\n",
      " [  0 797  52   0]\n",
      " [  0 316 179   0]\n",
      " [  0  21   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        88\n",
      "           1       0.66      0.94      0.77       849\n",
      "           2       0.73      0.36      0.48       495\n",
      "           3       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.67      1455\n",
      "   macro avg       0.35      0.33      0.31      1455\n",
      "weighted avg       0.63      0.67      0.62      1455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegression(random_state=10))\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy_lr = lr.score(X_test,y_test)\n",
    "confusion_mat_lr = confusion_matrix(y_test,y_pred)\n",
    "class_repo_lr = classification_report(y_test,y_pred)\n",
    "print(accuracy_lr)\n",
    "print(confusion_mat_lr)\n",
    "print(class_repo_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6364261168384879\n",
      "[[  1  77  10   0]\n",
      " [  0 810  39   0]\n",
      " [  0 380 115   0]\n",
      " [  0  21   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02        88\n",
      "           1       0.63      0.95      0.76       849\n",
      "           2       0.69      0.23      0.35       495\n",
      "           3       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.64      1455\n",
      "   macro avg       0.58      0.30      0.28      1455\n",
      "weighted avg       0.66      0.64      0.56      1455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "gnb = OneVsRestClassifier(MultinomialNB())\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "accuracy_gnb = gnb.score(X_test,y_test)\n",
    "confusion_mat_gnb = confusion_matrix(y_test,y_pred)\n",
    "class_repo_gnb = classification_report(y_test,y_pred)\n",
    "print(accuracy_gnb)\n",
    "print(confusion_mat_gnb)\n",
    "print(class_repo_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6460481099656358\n",
      "[[ 14  48  19   7]\n",
      " [  9 667 149  24]\n",
      " [  1 222 258  14]\n",
      " [  1  17   4   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.16      0.25        88\n",
      "           1       0.70      0.79      0.74       849\n",
      "           2       0.60      0.52      0.56       495\n",
      "           3       0.02      0.04      0.03        23\n",
      "\n",
      "    accuracy                           0.65      1455\n",
      "   macro avg       0.47      0.38      0.39      1455\n",
      "weighted avg       0.65      0.65      0.64      1455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "p = OneVsRestClassifier(Perceptron(max_iter=5))\n",
    "p.fit(X_train,y_train)\n",
    "y_pred = p.predict(X_test)\n",
    "accuracy_p = p.score(X_test,y_test)\n",
    "confusion_mat_p = confusion_matrix(y_test,y_pred)\n",
    "class_repo_p = classification_report(y_test,y_pred)\n",
    "print(accuracy_p)\n",
    "print(confusion_mat_p)\n",
    "print(class_repo_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6893470790378007\n",
      "[[ 21  48  18   1]\n",
      " [  9 726 107   7]\n",
      " [  6 232 255   2]\n",
      " [  2  16   4   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.24      0.33        88\n",
      "           1       0.71      0.86      0.78       849\n",
      "           2       0.66      0.52      0.58       495\n",
      "           3       0.09      0.04      0.06        23\n",
      "\n",
      "    accuracy                           0.69      1455\n",
      "   macro avg       0.50      0.41      0.44      1455\n",
      "weighted avg       0.68      0.69      0.67      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = OneVsRestClassifier(LinearSVC(random_state=10))\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy_svm = svm.score(X_test,y_test)\n",
    "confusion_mat_svm = confusion_matrix(y_test,y_pred)\n",
    "class_repo_svm = classification_report(y_test,y_pred)\n",
    "print(accuracy_svm)\n",
    "print(confusion_mat_svm)\n",
    "print(class_repo_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5532646048109966\n",
      "[[ 12  35  19  22]\n",
      " [  9 571 134 135]\n",
      " [  5 191 212  87]\n",
      " [  0  11   2  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.14      0.21        88\n",
      "           1       0.71      0.67      0.69       849\n",
      "           2       0.58      0.43      0.49       495\n",
      "           3       0.04      0.43      0.07        23\n",
      "\n",
      "    accuracy                           0.55      1455\n",
      "   macro avg       0.45      0.42      0.37      1455\n",
      "weighted avg       0.64      0.55      0.58      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = OneVsRestClassifier(DecisionTreeClassifier(random_state=10))\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy_dt = dt.score(X_test,y_test)\n",
    "confusion_mat_dt = confusion_matrix(y_test,y_pred)\n",
    "class_repo_dt = classification_report(y_test,y_pred)\n",
    "print(accuracy_dt)\n",
    "print(confusion_mat_dt)\n",
    "print(class_repo_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6048109965635738\n",
      "[[  6  67  14   1]\n",
      " [  3 797  44   5]\n",
      " [  1 417  76   1]\n",
      " [  0  22   0   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.07      0.12        88\n",
      "           1       0.61      0.94      0.74       849\n",
      "           2       0.57      0.15      0.24       495\n",
      "           3       0.12      0.04      0.06        23\n",
      "\n",
      "    accuracy                           0.60      1455\n",
      "   macro avg       0.48      0.30      0.29      1455\n",
      "weighted avg       0.59      0.60      0.52      1455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adb = AdaBoostClassifier(random_state=10)\n",
    "adb.fit(X_train,y_train)\n",
    "y_pred = adb.predict(X_test)\n",
    "accuracy_adb = adb.score(X_test,y_test)\n",
    "confusion_mat_adb = confusion_matrix(y_test,y_pred)\n",
    "class_repo_adb = classification_report(y_test,y_pred)\n",
    "print(accuracy_adb)\n",
    "print(confusion_mat_adb)\n",
    "print(class_repo_adb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.689347</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.679038</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.672165</th>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.670790</th>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.646048</th>\n",
       "      <td>Perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.636426</th>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.604811</th>\n",
       "      <td>AdaBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.553265</th>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model\n",
       "Score                               \n",
       "0.689347  Support Vector Machines   \n",
       "0.679038  Stochastic Gradient Decent\n",
       "0.672165  Random Forest             \n",
       "0.670790  Logistic Regression       \n",
       "0.646048  Perceptron                \n",
       "0.636426  Naive Bayes               \n",
       "0.604811  AdaBoost                  \n",
       "0.553265  Decision Tree             "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines','Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', \n",
    "              'Decision Tree',\"AdaBoost\"],\n",
    "    'Score': [accuracy_svm, accuracy_lr, \n",
    "              accuracy_rf, accuracy_gnb, accuracy_p, \n",
    "              accuracy_sgd, accuracy_dt,accuracy_adb]})\n",
    "acc_df = acc_df.sort_values(by='Score', ascending=False)\n",
    "acc_df = acc_df.set_index('Score')\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a11y2go</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abba</th>\n",
       "      <th>aber</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>zlf</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7277</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a11y2go  aapl  aaron   ab  abacus  abandoned  abba  aber  ability  able  \\\n",
       "7273  0.0      0.0   0.0    0.0  0.0     0.0        0.0   0.0   0.0      0.0    \n",
       "7274  0.0      0.0   0.0    0.0  0.0     0.0        0.0   0.0   0.0      0.0    \n",
       "7275  0.0      0.0   0.0    0.0  0.0     0.0        0.0   0.0   0.0      0.0    \n",
       "7276  0.0      0.0   0.0    0.0  0.0     0.0        0.0   0.0   0.0      0.0    \n",
       "7277  0.0      0.0   0.0    0.0  0.0     0.0        0.0   0.0   0.0      0.0    \n",
       "\n",
       "      ...  zlf  zms  zomb  zombie  zomg  zone  zoom  zuckerberg  zynga  zzs  \n",
       "7273  ...  0.0  0.0  0.0   0.0     0.0   0.0   0.0   0.0         0.0    0.0  \n",
       "7274  ...  0.0  0.0  0.0   0.0     0.0   0.0   0.0   0.0         0.0    0.0  \n",
       "7275  ...  0.0  0.0  0.0   0.0     0.0   0.0   0.0   0.0         0.0    0.0  \n",
       "7276  ...  0.0  0.0  0.0   0.0     0.0   0.0   0.0   0.0         0.0    0.0  \n",
       "7277  ...  0.0  0.0  0.0   0.0     0.0   0.0   0.0   0.0         0.0    0.0  \n",
       "\n",
       "[5 rows x 8268 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict(X_submission)\n",
    "result = pd.DataFrame(dict(zip(X_submission.index,pred_rf)).items(), columns = [\"tweet_id\", \"sentiment\"])\n",
    "result.to_csv(\"/Users/akankshamishra/Desktop/test_submission_new/result_rf.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt = dt.predict(X_submission)\n",
    "result = pd.DataFrame(dict(zip(X_submission.index,pred_dt)).items(), columns = [\"tweet_id\", \"sentiment\"])\n",
    "result.to_csv(\"/Users/akankshamishra/Desktop/test_submission_new/result_dt.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_adb = adb.predict(X_submission)\n",
    "result = pd.DataFrame(dict(zip(X_submission.index,pred_adb)).items(), columns = [\"tweet_id\", \"sentiment\"])\n",
    "result.to_csv(\"/Users/akankshamishra/Desktop/test_submission_new/result_adb.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_submission)\n",
    "result = pd.DataFrame(dict(zip(X_submission.index,pred_lr)).items(), columns = [\"tweet_id\", \"sentiment\"])\n",
    "result.to_csv(\"/Users/akankshamishra/Desktop/test_submission_new/result_lr.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_p = p.predict(X_submission)\n",
    "result = pd.DataFrame(dict(zip(X_submission.index,pred_p)).items(), columns = [\"tweet_id\", \"sentiment\"])\n",
    "result.to_csv(\"/Users/akankshamishra/Desktop/test_submission_new/result_p.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = svm.predict(X_submission)\n",
    "result = pd.DataFrame(dict(zip(X_submission.index,pred_svm)).items(), columns = [\"tweet_id\", \"sentiment\"])\n",
    "result.to_csv(\"/Users/akankshamishra/Desktop/test_submission_new/result_svm.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sgd = sgd.predict(X_submission)\n",
    "result = pd.DataFrame(dict(zip(X_submission.index,pred_sgd)).items(), columns = [\"tweet_id\", \"sentiment\"])\n",
    "result.to_csv(\"/Users/akankshamishra/Desktop/test_submission_new/result_sgd.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gnb = gnb.predict(X_submission)\n",
    "result = pd.DataFrame(dict(zip(X_submission.index,pred_gnb)).items(), columns = [\"tweet_id\", \"sentiment\"])\n",
    "result.to_csv(\"/Users/akankshamishra/Desktop/test_submission_new/result_gnb.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
